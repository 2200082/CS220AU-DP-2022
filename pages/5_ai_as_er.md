# Is Artifical Intelligence itself an Existential Risk?
In my last blog post about AI in general, I explored the different levels of AI. The third level, Artificial Superintelligence, was also introduced. In the literature, this was described as the state in which AI "would be capable of outperforming humans" ([levity.ai](https://levity.ai/blog/general-ai-vs-narrow-ai)). Therefore, in this post I would like to think about which scenarios there would be and to what extent these would allow AI to be classified as an existential risk.<br>
To do this, I would first like to learn more about artificial superintelligence.
## Definition
> „Artificial superintelligence (ASI) is a form of AI that is capable of surpassing human intelligence by manifesting cognitive skills and developing thinking skills of its own. Also known as super AI, artificial superintelligence is considered the most advanced, powerful, and intelligent type of AI that transcends the intelligence of some of the brightest minds, such as Albert Einstein” ([spiceworks.com](https://www.spiceworks.com/tech/artificial-intelligence/articles/super-artificial-intelligence/)).

According to spiceworks.com, ASI is able to acquire and develop all these human skills:<br><br>

<p align="center">
  <img src="/assets/img/asi.jpg">
</p>

If you take a closer look at when such a state of Artificial Super Intelligence could possibly occur, opinions differ. The majority of opinions, however, are found in a time span of 20 to 30 years: Louis Rosenberg - computer scientist and entrepreneur - speaks of 2030, Ray Kurzweil - computer scientist - of 2045 and Jurgen Schmidhuber - co-founder of NNAISENSE, a Swiss AI startup - of 2050. However, no one can predict with certainty whether and when such Artificial Superintelligence will exist ([levity.ai](https://levity.ai/blog/general-ai-vs-narrow-ai)).
## Characteristics
In the Journal of Artificial Intelligence Research 70 (2021), the following characteristics of ASI can be recognised ([spiceworks.com](https://www.spiceworks.com/tech/artificial-intelligence/articles/super-artificial-intelligence/)):
1. Because ASI will continually improve and grow more intelligent, it will be one of the best and perhaps the **final innovations** that humans will ever need to create.
2. The emergence of superintelligence will hasten **technological advancement** in a variety of areas, including academia, space exploration, pharmaceutical discovery and development, and many others.
3. ASI may further grow and produce sophisticated kinds of superintelligence that might even make it possible to **duplicate human minds**.
4. ASI may eventually result in the **technological singularity**.

## Potential Advantages
[Spiceworks.com](https://www.spiceworks.com/tech/artificial-intelligence/articles/super-artificial-intelligence/) identified five major potential advantages of ASI:<br><br>

<p align="center">
  <img src="/assets/img/asi_adv.jpg">
</p>

##### 1. Reduction in human error
By using ASI, errors that humans usually make unavoidable can be reduced. Especially in the case of syntactic, logical, arithmetic and resource-related problems, ASI can develop logic independently and minimise errors.
###### 2. Replace humans to accomplish risky tasks 
So while some tasks are too risky for humans (e.g. defusing a bomb) or outright impossible (e.g. working under nuclear radiation), such tasks could be accomplished with the help of superintelligent technologies such as robots. It is therefore a question of overcoming risk limitations.
##### 3. 24×7 Availability
With the help of super AI, the breaks that people have between their working hours (to sleep or have free time, for example) could be bridged, creating 24/7 availability in e.g. counselling centres. 
##### 4. Explore new science frontiers
Super AI tools can also be used to advance research. Especially in the field of space science, the extreme reasoning ability of super AI can be used to, for example, "test and estimate the probability of success of many equations, theories, research, rocket launches and space missions"
##### 5. Medical advances
Super AI can also bring benefits to the healthcare industry. “A 2020 research paper in Nature revealed the design and use of miniaturised intelligent nanorobots for intracellular drug delivery. […] With the addition of conscious superintelligence, the discovery and administration of new drug strains will become much more effective.”


## Risks
While some may emphasise the emerging opportunities, there are also those who are more critical of the whole development and point out the risks. Even though I have now discovered the characteristics and potentials of ASI, I am now more critical of ASI than I was at the beginning. <br>
The next step will be to look at the exact risks that ASI entails: <br><br>
Referring to the recent study published in the Journal of Artificial Intelligence Research in January 2021, it was found that "it would be almost impossible for humans to contain super AIs ([spiceworks.com](https://www.spiceworks.com/tech/artificial-intelligence/articles/super-artificial-intelligence/)). Let us now take a closer look at the risks associated with ASI in order to validate this very definitive statement.

<p align="center">
  <img src="/assets/img/asi_threats.jpg">
</p>

##### 1. Loss of control and understanding
...
##### 2. The weaponization of super AI
...
##### 3. Failure to align human and AI goals
...
##### 4. Malevolent superintelligence
...
##### 5. The danger of nuclear attacks
...
##### 6. Ethical implications
...

## Conclusion
...
## Navigation
Back to the Post about [Artificial Intelligence](4_ai.md)!<br>
Take me to the Post about [AI as indirect Influence on Existential Risks](6_ai_and_politics.md)!<br>
